"""
Script pour vÃ©rifier comment le modÃ¨le interprÃ¨te les classes
et dÃ©terminer si 0 = normal ou 1 = normal
"""

import joblib
import numpy as np
from pathlib import Path

MODEL_DIR = Path(__file__).parent / "models"
MODEL_PATH = MODEL_DIR / "random_forest_model.pkl"

def verifier_interpretation():
    """VÃ©rifie l'interprÃ©tation des classes du modÃ¨le"""
    
    print("=" * 70)
    print("  VÃ‰RIFICATION DE L'INTERPRÃ‰TATION DU MODÃˆLE")
    print("=" * 70)
    print()
    
    if not MODEL_PATH.exists():
        print(f"âŒ ModÃ¨le non trouvÃ©: {MODEL_PATH}")
        return
    
    # Charger le modÃ¨le
    model = joblib.load(MODEL_PATH)
    print(f"âœ… ModÃ¨le chargÃ©: {type(model).__name__}")
    
    # VÃ©rifier si c'est un RandomForestClassifier
    from sklearn.ensemble import RandomForestClassifier
    if not isinstance(model, RandomForestClassifier):
        print(f"âš ï¸  Ce n'est pas un RandomForestClassifier, mais {type(model).__name__}")
    
    # VÃ©rifier les classes
    if hasattr(model, 'classes_'):
        classes = model.classes_
        print(f"\nğŸ“‹ Classes du modÃ¨le: {classes}")
        print(f"   Nombre de classes: {len(classes)}")
        
        # GÃ©nÃ©rer des donnÃ©es de test
        n_features = model.n_features_in_ if hasattr(model, 'n_features_in_') else 29
        
        print(f"\nğŸ§ª Test avec des donnÃ©es synthÃ©tiques...")
        print(f"   Nombre de features: {n_features}")
        
        # CrÃ©er plusieurs transactions de test
        test_cases = [
            ("Transaction trÃ¨s normale", np.zeros((1, n_features))),
            ("Transaction normale", np.random.randn(1, n_features) * 0.5),
            ("Transaction suspecte", np.random.randn(1, n_features) * 3),
        ]
        
        for name, test_data in test_cases:
            try:
                prediction = model.predict(test_data)[0]
                proba = model.predict_proba(test_data)[0]
                
                print(f"\n   {name}:")
                print(f"      Prediction: {prediction} (classe {prediction})")
                print(f"      ProbabilitÃ©s: {proba}")
                for i, prob in enumerate(proba):
                    print(f"         Classe {classes[i]}: {prob:.4f} ({prob*100:.2f}%)")
                
                # InterprÃ©tation
                if len(proba) == 2:
                    if proba[0] > proba[1]:
                        print(f"      â†’ Classe {classes[0]} est plus probable (prob={proba[0]:.4f})")
                    else:
                        print(f"      â†’ Classe {classes[1]} est plus probable (prob={proba[1]:.4f})")
                        
            except Exception as e:
                print(f"   âŒ Erreur avec {name}: {e}")
    
    # VÃ©rifier l'ordre standard
    print(f"\n" + "=" * 70)
    print("  INTERPRÃ‰TATION STANDARD")
    print("=" * 70)
    print()
    print("Dans sklearn RandomForestClassifier:")
    print("  - predict_proba() retourne [prob_classe_0, prob_classe_1]")
    print("  - predict() retourne la classe prÃ©dite (0 ou 1)")
    print()
    print("Si le modÃ¨le a Ã©tÃ© entraÃ®nÃ© avec:")
    print("  - Class 0 = normal")
    print("  - Class 1 = fraude")
    print()
    print("Alors:")
    print("  - proba[0] = probabilitÃ© d'Ãªtre normal (0.00 Ã  1.00)")
    print("  - proba[1] = probabilitÃ© d'Ãªtre fraude (0.00 Ã  1.00)")
    print()
    print("  - prediction = 0 â†’ transaction normale")
    print("  - prediction = 1 â†’ transaction frauduleuse")
    print()
    print("  - proba[1] = 0.00 â†’ 0% de chance d'Ãªtre fraude â†’ NORMAL")
    print("  - proba[1] = 1.00 â†’ 100% de chance d'Ãªtre fraude â†’ FRAUDE")
    
    print(f"\n" + "=" * 70)

if __name__ == "__main__":
    verifier_interpretation()
