"""
Script pour diagnostiquer le mod√®le Random Forest et identifier les probl√®mes de compatibilit√©
"""

import joblib
import json
import numpy as np
from pathlib import Path
import traceback

MODEL_DIR = Path(__file__).parent / "models"
MODEL_PATH = MODEL_DIR / "random_forest_model.pkl"
SCALER_PATH = MODEL_DIR / "scaler.pkl"
FEATURES_PATH = MODEL_DIR / "feature_columns.json"

def diagnose_model():
    """Diagnostique le mod√®le et identifie les probl√®mes"""
    
    print("=" * 70)
    print("  DIAGNOSTIC DU MOD√àLE RANDOM FOREST")
    print("=" * 70)
    print()
    
    # 1. V√©rifier l'existence des fichiers
    print("üìÅ V√©rification des fichiers...")
    print(f"   R√©pertoire: {MODEL_DIR}")
    print(f"   Existe: {MODEL_DIR.exists()}")
    
    if MODEL_DIR.exists():
        files = list(MODEL_DIR.glob("*"))
        print(f"   Fichiers dans le r√©pertoire:")
        for f in files:
            print(f"     - {f.name}")
    
    if not MODEL_PATH.exists():
        print(f"\n‚ùå ERREUR: Mod√®le non trouv√© √† {MODEL_PATH}")
        print(f"   Veuillez placer random_forest_model.pkl dans {MODEL_DIR}")
        return False
    
    print(f"   ‚úÖ Mod√®le trouv√©: {MODEL_PATH}")
    
    # 2. Charger et analyser le mod√®le
    print("\nüì¶ Analyse du mod√®le...")
    try:
        model = joblib.load(MODEL_PATH)
        print(f"   Type: {type(model).__name__}")
        
        # Nombre de features
        if hasattr(model, 'n_features_in_'):
            n_features_model = model.n_features_in_
            print(f"   ‚úÖ Features attendues: {n_features_model}")
        else:
            print(f"   ‚ö†Ô∏è  n_features_in_ non disponible")
            n_features_model = None
        
        # Noms des features
        model_feature_names = None
        if hasattr(model, 'feature_names_in_'):
            if model.feature_names_in_ is not None:
                model_feature_names = list(model.feature_names_in_)
                print(f"   ‚úÖ Noms des features du mod√®le ({len(model_feature_names)}):")
                for i, name in enumerate(model_feature_names, 1):
                    print(f"      {i}. {name}")
            else:
                print(f"   ‚ö†Ô∏è  feature_names_in_ est None")
        else:
            print(f"   ‚ö†Ô∏è  feature_names_in_ non disponible")
        
        # M√©thodes disponibles
        has_predict = hasattr(model, 'predict')
        has_predict_proba = hasattr(model, 'predict_proba')
        print(f"\n   M√©thodes disponibles:")
        print(f"      predict: {'‚úÖ' if has_predict else '‚ùå'}")
        print(f"      predict_proba: {'‚úÖ' if has_predict_proba else '‚ùå'}")
        
    except Exception as e:
        print(f"   ‚ùå Erreur lors du chargement: {e}")
        traceback.print_exc()
        return False
    
    # 3. Analyser le scaler
    print("\nüì¶ Analyse du scaler...")
    scaler = None
    scaler_feature_names = None
    scaler_n_features = None
    
    if SCALER_PATH.exists():
        try:
            scaler = joblib.load(SCALER_PATH)
            print(f"   Type: {type(scaler).__name__}")
            
            if hasattr(scaler, 'n_features_in_'):
                scaler_n_features = scaler.n_features_in_
                print(f"   ‚úÖ Features attendues: {scaler_n_features}")
            
            if hasattr(scaler, 'feature_names_in_') and scaler.feature_names_in_ is not None:
                scaler_feature_names = list(scaler.feature_names_in_)
                print(f"   ‚úÖ Noms des features ({len(scaler_feature_names)}):")
                for i, name in enumerate(scaler_feature_names, 1):
                    print(f"      {i}. {name}")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Erreur lors du chargement: {e}")
    else:
        print(f"   ‚ö†Ô∏è  Scaler non trouv√© (optionnel)")
    
    # 4. Analyser feature_columns.json
    print("\nüì¶ Analyse des features...")
    feature_columns = None
    if FEATURES_PATH.exists():
        try:
            with open(FEATURES_PATH, 'r') as f:
                feature_columns = json.load(f)
            print(f"   ‚úÖ Features charg√©es ({len(feature_columns)}):")
            print(f"      {feature_columns}")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Erreur lors du chargement: {e}")
    else:
        print(f"   ‚ö†Ô∏è  feature_columns.json non trouv√©")
        feature_columns = [f'V{i+1}' for i in range(28)] + ['Amount']
        print(f"   Utilisation des features par d√©faut ({len(feature_columns)}):")
        print(f"      {feature_columns}")
    
    # 5. V√©rifier la compatibilit√©
    print("\nüîç V√©rification de compatibilit√©...")
    
    issues = []
    
    # V√©rifier nombre de features
    if n_features_model is not None and feature_columns is not None:
        if n_features_model != len(feature_columns):
            issues.append(f"‚ùå Incompatibilit√©: Le mod√®le attend {n_features_model} features, mais {len(feature_columns)} sont d√©finies")
        else:
            print(f"   ‚úÖ Nombre de features compatible: {n_features_model}")
    
    # V√©rifier les noms de features
    if model_feature_names is not None and feature_columns is not None:
        if set(model_feature_names) != set(feature_columns):
            missing = set(model_feature_names) - set(feature_columns)
            extra = set(feature_columns) - set(model_feature_names)
            if missing:
                issues.append(f"‚ùå Features manquantes dans feature_columns.json: {missing}")
            if extra:
                issues.append(f"‚ùå Features suppl√©mentaires dans feature_columns.json: {extra}")
        else:
            print(f"   ‚úÖ Noms des features compatibles")
    
    # V√©rifier le scaler
    if scaler_n_features is not None and n_features_model is not None:
        if scaler_n_features != n_features_model:
            issues.append(f"‚ö†Ô∏è  Le scaler attend {scaler_n_features} features, le mod√®le en attend {n_features_model}")
    
    if scaler_feature_names is not None and model_feature_names is not None:
        if set(scaler_feature_names) != set(model_feature_names):
            issues.append(f"‚ö†Ô∏è  Les noms de features du scaler ne correspondent pas √† ceux du mod√®le")
    
    # 6. R√©sum√© et recommandations
    print("\n" + "=" * 70)
    print("  R√âSUM√â")
    print("=" * 70)
    
    if issues:
        print("\n‚ùå PROBL√àMES D√âTECT√âS:")
        for issue in issues:
            print(f"   {issue}")
    else:
        print("\n‚úÖ Aucun probl√®me de compatibilit√© d√©tect√©!")
    
    # 7. Tester une pr√©diction
    print("\nüß™ Test de pr√©diction...")
    try:
        # D√©terminer le nombre de features √† utiliser
        if n_features_model is not None:
            n_features = n_features_model
        elif feature_columns is not None:
            n_features = len(feature_columns)
        else:
            n_features = 29  # V1-V28 + Amount par d√©faut
        
        # Cr√©er des donn√©es de test
        test_data = np.random.randn(1, n_features).astype(np.float32)
        print(f"   Donn√©es de test cr√©√©es: shape {test_data.shape}")
        
        # Si le mod√®le a des noms de features, utiliser un DataFrame
        if model_feature_names is not None:
            try:
                import pandas as pd
                test_df = pd.DataFrame(test_data, columns=model_feature_names)
                prediction = model.predict(test_df)[0]
                print(f"   ‚úÖ Pr√©diction r√©ussie: {prediction}")
                
                if has_predict_proba:
                    proba = model.predict_proba(test_df)[0]
                    print(f"   ‚úÖ Probabilit√©s: normal={proba[0]:.4f}, fraude={proba[1]:.4f}")
            except ImportError:
                print(f"   ‚ö†Ô∏è  pandas non disponible, utilisation sans DataFrame")
                prediction = model.predict(test_data)[0]
                print(f"   ‚úÖ Pr√©diction r√©ussie: {prediction}")
        else:
            prediction = model.predict(test_data)[0]
            print(f"   ‚úÖ Pr√©diction r√©ussie: {prediction}")
            
            if has_predict_proba:
                proba = model.predict_proba(test_data)[0]
                print(f"   ‚úÖ Probabilit√©s: normal={proba[0]:.4f}, fraude={proba[1]:.4f}")
        
        print("\n‚úÖ Le mod√®le peut effectuer des pr√©dictions!")
        
    except Exception as e:
        print(f"\n‚ùå ERREUR lors du test de pr√©diction: {e}")
        traceback.print_exc()
        issues.append(f"‚ùå Le mod√®le ne peut pas faire de pr√©diction: {e}")
    
    # 8. G√©n√©rer feature_columns.json si n√©cessaire
    if model_feature_names is not None and not FEATURES_PATH.exists():
        print("\nüí° Recommandation: Cr√©er feature_columns.json...")
        try:
            with open(FEATURES_PATH, 'w') as f:
                json.dump(model_feature_names, f, indent=2)
            print(f"   ‚úÖ feature_columns.json cr√©√© avec les features du mod√®le")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Impossible de cr√©er feature_columns.json: {e}")
    
    print("\n" + "=" * 70)
    
    return len(issues) == 0

if __name__ == "__main__":
    success = diagnose_model()
    if not success:
        print("\n‚ùå Des probl√®mes ont √©t√© d√©tect√©s. Veuillez les corriger avant d'utiliser le mod√®le.")
    else:
        print("\n‚úÖ Le mod√®le est pr√™t √† √™tre utilis√©!")
